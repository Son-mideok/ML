{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a824d2d",
   "metadata": {},
   "source": [
    "## 1 Bag of Words(BoW)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79079f09",
   "metadata": {},
   "source": [
    "#### 1.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6baa4926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'정부': 0, '가': 1, '발표': 2, '하는': 3, '물가상승률': 4, '과': 5, '소비자': 6, '느끼는': 7, '은': 8, '다르다': 9}\n",
      "bag of words vector : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Okt\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "def build_bag_of_words(document):\n",
    "    document = document.replace('.', '')\n",
    "    tokenized_document = okt.morphs(document)\n",
    "    \n",
    "    word_to_index = {}\n",
    "    bow = []\n",
    "    \n",
    "    for word in tokenized_document:\n",
    "        if word not in word_to_index.keys():    # 단어가 처음 나왔을 경우\n",
    "            word_to_index[word] = len(word_to_index)\n",
    "            bow.insert(len(word_to_index) - 1, 1) # 처음나왔을때 무조건 1\n",
    "        \n",
    "        else:   # 반복해서 나올때 세줘야함\n",
    "            index = word_to_index.get(word)\n",
    "            bow[index] = bow[index] + 1\n",
    "            \n",
    "            \n",
    "        \n",
    "    return word_to_index, bow\n",
    "\n",
    "# 단어가 몇번 나왔나\n",
    "\n",
    "doc1 = \"정부가 발표하는 물가상승률과 소비자가 느끼는 물가상승률은 다르다.\"\n",
    "vocab, bow = build_bag_of_words(doc1)\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecc226b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocabulary : {'소비자': 0, '는': 1, '주로': 2, '소비': 3, '하는': 4, '상품': 5, '을': 6, '기준': 7, '으로': 8, '물가상승률': 9, '느낀다': 10}\n",
      "bag of words vector : [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "doc2 = '소비자는 주로 소비하는 상품을 기준으로 물가상승률을 느낀다.'\n",
    "vocab, bow = build_bag_of_words(doc2)\n",
    "\n",
    "print('vocabulary :', vocab)\n",
    "print('bag of words vector :', bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f320f006",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = doc1 + ' ' + doc2\n",
    "vocab, bow = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85785f5b",
   "metadata": {},
   "source": [
    "### 1.2 BOW-CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68b89511",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 2 1 2 1]]\n",
      "vocabulary : {'you': 4, 'know': 1, 'want': 3, 'your': 5, 'love': 2, 'because': 0}\n"
     ]
    }
   ],
   "source": [
    "# CountVectorizer 띄어쓰기만 가능, 한국어에 적합하지 않다, 영어중심\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = ['you know I want your love. because I love you.']\n",
    "vector = CountVectorizer()\n",
    "\n",
    "# 빈도수 기록\n",
    "print('bag of words vector :', vector.fit_transform(corpus).toarray())\n",
    "\n",
    "# 단어 인덱스\n",
    "print('vocabulary :', vector.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae97cc4",
   "metadata": {},
   "source": [
    "### 1.3 BOW-불용어 제거\n",
    "- BOW 쓰는 이유: 횟수로 중요한 단어 찾아내는거, 횟수 작은거 불용어로 들어가게 하는거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2dfd787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4aefa74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 4, 'it': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "# 사용자정의 불용어 적용\n",
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=[\"the\", \"a\", \"an\", \"is\", \"not\"])\n",
    "\n",
    "print('bag of words vector :' ,vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a373666",
   "metadata": {},
   "source": [
    "### 1.4 BOW-불용어 제거(CountVectorizer 포함된 불용어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6e4ca2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1]]\n",
      "vocabulary : {'family': 0, 'important': 1, 'thing': 2}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "vect = CountVectorizer(stop_words=\"english\")\n",
    "\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f89748",
   "metadata": {},
   "source": [
    "### 1.5 BOW-불용어 제거(NLTK 포함된 불용어)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65fcffa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bag of words vector : [[1 1 1 1]]\n",
      "vocabulary : {'family': 1, 'important': 2, 'thing': 3, 'everything': 0}\n"
     ]
    }
   ],
   "source": [
    "text = [\"Family is not an important thing. It's everything.\"]\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "vect = CountVectorizer(stop_words=stop_words)\n",
    "print('bag of words vector :',vect.fit_transform(text).toarray())\n",
    "print('vocabulary :',vect.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9ced33",
   "metadata": {},
   "source": [
    "## 2 문서 단어 행렬(Document-Term Matrix, DTM)\n",
    "- 문제점 : 0 이 많다, 단어텀이 많다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e038f70f",
   "metadata": {},
   "source": [
    "#### 2.0.1 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c0b45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab : wget -c https://raw.githubusercontent.com/euphoris/datasets/master/imdb.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa7df106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py): started\n",
      "  Building wheel for wget (setup.py): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=bf4b9bde4e237429116354d03b484e93f05abf0164015a498c56fba6235a7757\n",
      "  Stored in directory: c:\\users\\virtue\\appdata\\local\\pip\\cache\\wheels\\04\\5f\\3e\\46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d49f80bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "  0% [                                                                              ]     0 / 55772\r",
      " 14% [...........                                                                   ]  8192 / 55772\r",
      " 29% [......................                                                        ] 16384 / 55772\r",
      " 44% [..................................                                            ] 24576 / 55772\r",
      " 58% [.............................................                                 ] 32768 / 55772\r",
      " 73% [.........................................................                     ] 40960 / 55772\r",
      " 88% [....................................................................          ] 49152 / 55772\r",
      "100% [..............................................................................] 55772 / 55772"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'imdb (1).xlsx'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# windows\n",
    "import wget\n",
    "\n",
    "wget.download('https://raw.githubusercontent.com/euphoris/datasets/master/imdb.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1476523",
   "metadata": {},
   "source": [
    "#### 2.0.2 데이터 열기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35a94dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel('imdb (1).xlsx', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a01edff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  A very, very, very slow-moving, aimless movie ...          0\n",
       "1  Not sure who was more lost - the flat characte...          0\n",
       "2  Attempting artiness with black & white and cle...          0\n",
       "3       Very little music or anything to speak of.            0\n",
       "4  The best scene in the movie was when Gerardo i...          1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ce45d9",
   "metadata": {},
   "source": [
    "### 2.3 TDM 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d2911d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# max_features : 빈도순으로 최대 500단어까지 포함\n",
    "# stop_words='english' : 불용어(관사, 전치사등을 제거)\n",
    "cv = CountVectorizer(max_features=500, stop_words='english') \n",
    "#숫자는 바꿔보고 잘 나오는걸로 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4dddb525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<748x500 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 3434 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm = cv.fit_transform(df['review']) # 콜론에 맞게 변환, 띄어쓰기 기준으로 단어 자름\n",
    "tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53bb6007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(748, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4462a2e",
   "metadata": {},
   "source": [
    "### 2.4 단어 목록"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2b99100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\virtue\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['10',\n",
       " '20',\n",
       " '90',\n",
       " 'absolutely',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'actress']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 단어 목록을 볼때는 tdm이 아니라 cv에 저장되어 있음, 단어가 피쳐, 기본함수만 사용하면 500개 단어가 나옴\n",
    "cv.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a6af4089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cv.get_feature_names()) # 500개 단어있는지 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120f9041",
   "metadata": {},
   "source": [
    "### 2.5 단어별 총 빈도"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
